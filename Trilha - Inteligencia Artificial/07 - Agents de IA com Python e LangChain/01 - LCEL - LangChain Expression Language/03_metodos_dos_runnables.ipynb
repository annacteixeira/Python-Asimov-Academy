{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Principais métodos de chains com LCEL\n",
    "\n",
    "A interface padrão de LCEL inclui os seguintes métodos:\n",
    "\n",
    "- **stream:** transmitir de volta fragmentos da resposta\n",
    "- **invoke:** chamar a cadeia com um input\n",
    "- **batch:** chamar a cadeia com uma lista de inputs\n",
    "\n",
    "Esses também possuem métodos assíncronos correspondentes que devem ser usados com a sintaxe `asyncio await` para concorrência:\n",
    "\n",
    "- **astream:** transmitir de volta fragmentos da resposta de forma assíncrona\n",
    "- **ainvoke:** chamar a cadeia com um input de forma assíncrona\n",
    "- **abatch:** chamar a cadeia com uma lista de inputs de forma assíncrona\n",
    "- **astream_log:** transmitir de volta etapas intermediárias à medida que acontecem, além da resposta final\n",
    "- **astream_events:** transmitir eventos beta à medida que acontecem na cadeia"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv, find_dotenv\n",
    "\n",
    "_ = load_dotenv(find_dotenv())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "\n",
    "model = ChatOpenAI(model=\"gpt-3.5-turbo-0125\")\n",
    "prompt = ChatPromptTemplate.from_template(\"Crie uma frase sobre o assunto: {assunto}\")\n",
    "\n",
    "chain = prompt | model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Invoke\n",
    "\n",
    "O invoke é o método básico para inserir uma input na cadeia e receber uma resposta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='Cachorrinhos são seres cheios de amor e lealdade, capazes de alegrar nossos dias com sua presença e companhia incondicional.', response_metadata={'token_usage': {'completion_tokens': 39, 'prompt_tokens': 20, 'total_tokens': 59, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-3.5-turbo-0125', 'system_fingerprint': None, 'finish_reason': 'stop', 'logprobs': None}, id='run-743f0750-7bab-44de-85c4-aa67db1adbba-0')"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain.invoke({'assunto': 'cachorrinhos'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='Cachorrinhos são como pequenos raios de sol que iluminam nossos dias com amor e alegria.', response_metadata={'token_usage': {'completion_tokens': 29, 'prompt_tokens': 20, 'total_tokens': 49, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-3.5-turbo-0125', 'system_fingerprint': None, 'finish_reason': 'stop', 'logprobs': None}, id='run-d41c477f-9615-4d2b-9f62-62c6a640fbc7-0')"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain.invoke('cachorrinhos')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stream\n",
    "\n",
    "Para recebermos uma saída conforme ela é gerada pelo modelo utilizamos o stream\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "O cachorrinho é o melhor amigo do homem, sempre fiel e amoroso em todas as horas."
     ]
    }
   ],
   "source": [
    "for chunck in chain.stream({'assunto': 'cachorrinho'}):\n",
    "    print(chunck.content, end='', flush=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Batch\n",
    "\n",
    "Para fazermos múltimpas requisições em paralelo utilizamos o batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[AIMessage(content='Cachorrinhos são companheiros leais que enchem nossos dias de amor e alegria com suas travessuras e carinho.', response_metadata={'token_usage': {'completion_tokens': 33, 'prompt_tokens': 20, 'total_tokens': 53, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-3.5-turbo-0125', 'system_fingerprint': None, 'finish_reason': 'stop', 'logprobs': None}, id='run-d0f46091-5b66-48af-aa73-0f0ac74a83c3-0'),\n",
       " AIMessage(content='\"O ronronar de um gatinho é a canção mais doce que acalma a alma.\"', response_metadata={'token_usage': {'completion_tokens': 26, 'prompt_tokens': 19, 'total_tokens': 45, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-3.5-turbo-0125', 'system_fingerprint': None, 'finish_reason': 'stop', 'logprobs': None}, id='run-e45eaec8-2c32-4ed8-bbc4-b3112e1ad960-0'),\n",
       " AIMessage(content='Os cavalinhos de carrossel sempre trazem alegria e diversão para as crianças em parques de diversões.', response_metadata={'token_usage': {'completion_tokens': 30, 'prompt_tokens': 19, 'total_tokens': 49, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-3.5-turbo-0125', 'system_fingerprint': None, 'finish_reason': 'stop', 'logprobs': None}, id='run-1b62b5b7-8b94-4788-8dfc-140cd89f54c3-0')]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain.batch([{'assunto': 'cachorrinhos'}, {'assunto': 'gatinho'}, {'assunto': 'cavalinhos'}])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[AIMessage(content='Os cachorrinhos são amigos leais que aquecem nossos corações com sua alegria e amor incondicional.', response_metadata={'token_usage': {'completion_tokens': 28, 'prompt_tokens': 20, 'total_tokens': 48, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-3.5-turbo-0125', 'system_fingerprint': None, 'finish_reason': 'stop', 'logprobs': None}, id='run-326a2323-9cc5-428b-a8cb-613274c87221-0'),\n",
       " AIMessage(content='O gatinho é o companheiro perfeito para alegrar nossos dias com sua fofura e carinho.', response_metadata={'token_usage': {'completion_tokens': 27, 'prompt_tokens': 19, 'total_tokens': 46, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-3.5-turbo-0125', 'system_fingerprint': None, 'finish_reason': 'stop', 'logprobs': None}, id='run-f182cf63-8f3a-40cd-9eee-9042bb802f7b-0'),\n",
       " AIMessage(content='Os cavalinhos de carrossel são a alegria das crianças em parques de diversões.', response_metadata={'token_usage': {'completion_tokens': 24, 'prompt_tokens': 19, 'total_tokens': 43, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-3.5-turbo-0125', 'system_fingerprint': None, 'finish_reason': 'stop', 'logprobs': None}, id='run-90aeedee-7975-4422-9614-8ea7fd8de9b4-0')]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain.batch([{'assunto': 'cachorrinhos'}, {'assunto': 'gatinho'}, {'assunto': 'cavalinhos'}], config={'max_concurrency': 5})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ainvoke\n",
    "\n",
    "Todos os métodos possuem assíncronos correspondentes que devem ser usados com a sintaxe `asyncio await` para concorrência"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import asyncio\n",
    "\n",
    "async def processa_chain(input):\n",
    "    resposta = await chain.ainvoke(input)\n",
    "    return resposta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='Cachorrinhos são a prova de que o amor incondicional pode vir em formas peludas e com quatro patas.', response_metadata={'token_usage': {'completion_tokens': 29, 'prompt_tokens': 20, 'total_tokens': 49, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-3.5-turbo-0125', 'system_fingerprint': None, 'finish_reason': 'stop', 'logprobs': None}, id='run-c4d1fee5-f08a-4fc3-8a02-60ea105055d5-0')"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "task1 = asyncio.create_task(processa_chain({'assunto': 'gatinho'}))\n",
    "task2 = asyncio.create_task(processa_chain({'assunto': 'cavalinhos'}))\n",
    "task3 = asyncio.create_task(processa_chain({'assunto': 'cachorrinhos'}))\n",
    "\n",
    "await task1\n",
    "await task2\n",
    "await task3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='Os cavalinhos de brinquedo são a diversão preferida das crianças em parques e festas.', response_metadata={'token_usage': {'completion_tokens': 25, 'prompt_tokens': 19, 'total_tokens': 44, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-3.5-turbo-0125', 'system_fingerprint': None, 'finish_reason': 'stop', 'logprobs': None}, id='run-f92191f8-ad2f-47cf-90dd-0850bcd7b82e-0')"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "task2.result()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculando a diferença de tempo ao utilizar async"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.4262347221374512\n"
     ]
    }
   ],
   "source": [
    "from time import time\n",
    "\n",
    "a = time()\n",
    "\n",
    "task1 = asyncio.create_task(processa_chain({'assunto': 'gatinho'}))\n",
    "task2 = asyncio.create_task(processa_chain({'assunto': 'cavalinhos'}))\n",
    "task3 = asyncio.create_task(processa_chain({'assunto': 'cachorrinhos'}))\n",
    "\n",
    "await task1\n",
    "await task2\n",
    "await task3\n",
    "\n",
    "b = time()\n",
    "print(b-a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.151465892791748\n"
     ]
    }
   ],
   "source": [
    "from time import time\n",
    "\n",
    "a = time()\n",
    "\n",
    "task1 = chain.invoke({'assunto': 'gatinho'})\n",
    "task2 = chain.invoke({'assunto': 'cavalinhos'})\n",
    "task3 = chain.invoke({'assunto': 'cachorrinhos'})\n",
    "\n",
    "b = time()\n",
    "print(b-a)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
