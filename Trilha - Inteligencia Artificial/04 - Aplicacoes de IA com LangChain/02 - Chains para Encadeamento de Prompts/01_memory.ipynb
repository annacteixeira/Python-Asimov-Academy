{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Memory\n",
    "\n",
    "A maioria das aplicações de Modelos de LLM possui uma interface conversacional. Um componente essencial de uma conversa é a capacidade de se referir a informações introduzidas anteriormente na conversa. No mínimo, um sistema conversacional deve ser capaz de acessar diretamente alguma janela de mensagens passadas. Um sistema mais complexo precisará ter um modelo de mundo que está constantemente atualizando, o que lhe permite fazer coisas como manter informações sobre entidades e suas relações.\n",
    "\n",
    "Chamamos essa capacidade de armazenar informações sobre interações passadas de 'Memory', ou memória. LangChain oferece muitas utilidades para adicionar memória a um sistema. Essas utilidades podem ser usadas por si só ou incorporadas de maneira integrada em uma chain."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\annaf\\AppData\\Local\\Temp\\ipykernel_7700\\1267886439.py:6: LangChainDeprecationWarning: The class `OpenAI` was deprecated in LangChain 0.0.10 and will be removed in 1.0. An updated version of the class exists in the :class:`~langchain-openai package and should be used instead. To use it run `pip install -U :class:`~langchain-openai` and import as `from :class:`~langchain_openai import OpenAI``.\n",
      "  llm = OpenAI(model='gpt-3.5-turbo-instruct')\n"
     ]
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "\n",
    "from langchain.llms import OpenAI\n",
    "\n",
    "llm = OpenAI(model='gpt-3.5-turbo-instruct')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\annaf\\AppData\\Local\\Temp\\ipykernel_7700\\3580805746.py:3: LangChainDeprecationWarning: Please see the migration guide at: https://python.langchain.com/docs/versions/migrating_memory/\n",
      "  memory = ConversationBufferMemory()\n"
     ]
    }
   ],
   "source": [
    "from langchain.memory import ConversationBufferMemory\n",
    "\n",
    "memory = ConversationBufferMemory()\n",
    "\n",
    "memory.chat_memory.add_user_message('Oi?')\n",
    "memory.chat_memory.add_ai_message('Oi! Como posso te ajudar?')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'history': 'Human: Oi?\\nAI: Oi! Como posso te ajudar?'}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "memory.load_memory_variables({})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Criando uma conversa com memória"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.memory import ConversationBufferMemory\n",
    "\n",
    "memory = ConversationBufferMemory(return_messages=True)\n",
    "\n",
    "memory.chat_memory.add_user_message('Oi?')\n",
    "memory.chat_memory.add_ai_message('Oi! Como posso te ajudar?')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'history': [HumanMessage(content='Oi?', additional_kwargs={}, response_metadata={}),\n",
       "  AIMessage(content='Oi! Como posso te ajudar?', additional_kwargs={}, response_metadata={})]}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "memory.load_memory_variables({})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\annaf\\AppData\\Local\\Temp\\ipykernel_7700\\272160588.py:6: LangChainDeprecationWarning: The class `ConversationChain` was deprecated in LangChain 0.2.7 and will be removed in 1.0. Use :meth:`~RunnableWithMessageHistory: https://python.langchain.com/v0.2/api_reference/core/runnables/langchain_core.runnables.history.RunnableWithMessageHistory.html` instead.\n",
      "  conversation = ConversationChain(\n"
     ]
    }
   ],
   "source": [
    "from langchain_openai.chat_models import ChatOpenAI\n",
    "from langchain.chains.conversation.base import ConversationChain\n",
    "\n",
    "chat = ChatOpenAI()\n",
    "memory = ConversationBufferMemory()\n",
    "conversation = ConversationChain(\n",
    "    llm=chat,\n",
    "    memory=memory,\n",
    "    verbose=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new ConversationChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mThe following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.\n",
      "\n",
      "Current conversation:\n",
      "\n",
      "Human: Olá! Meu nome é Anna\n",
      "AI:\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Olá Anna! É um prazer conhecê-la. Como posso ajudá-la hoje?'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conversation.predict(input='Olá! Meu nome é Anna')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new ConversationChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mThe following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.\n",
      "\n",
      "Current conversation:\n",
      "Human: Olá! Meu nome é Anna\n",
      "AI: Olá Anna! É um prazer conhecê-la. Como posso ajudá-la hoje?\n",
      "Human: Qual é meu nome?\n",
      "AI:\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Seu nome é Anna! Você acabou de me dizer. Como posso ajudá-la mais hoje, Anna?'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conversation.predict(input='Qual é meu nome?')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'history': 'Human: Olá! Meu nome é Anna\\nAI: Olá Anna! É um prazer conhecê-la. Como posso ajudá-la hoje?\\nHuman: Qual é meu nome?\\nAI: Seu nome é Anna! Você acabou de me dizer. Como posso ajudá-la mais hoje, Anna?'}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "memory.load_memory_variables({})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ConversationBufferWindowMemory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.memory import ConversationBufferWindowMemory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\annaf\\AppData\\Local\\Temp\\ipykernel_7700\\3193028927.py:5: LangChainDeprecationWarning: Please see the migration guide at: https://python.langchain.com/docs/versions/migrating_memory/\n",
      "  memory = ConversationBufferWindowMemory(k=1)\n"
     ]
    }
   ],
   "source": [
    "from langchain_openai.chat_models import ChatOpenAI\n",
    "from langchain.chains.conversation.base import ConversationChain\n",
    "\n",
    "chat = ChatOpenAI()\n",
    "memory = ConversationBufferWindowMemory(k=1)\n",
    "conversation = ConversationChain(\n",
    "    llm=chat,\n",
    "    memory=memory,\n",
    "    verbose=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new ConversationChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mThe following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.\n",
      "\n",
      "Current conversation:\n",
      "\n",
      "Human: Olá, meu nome é Anna\n",
      "AI:\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Olá, Anna! É um prazer conhecê-la. Como posso ajudá-la hoje?'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conversation.predict(input='Olá, meu nome é Anna')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new ConversationChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mThe following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.\n",
      "\n",
      "Current conversation:\n",
      "Human: Olá, meu nome é Anna\n",
      "AI: Olá, Anna! É um prazer conhecê-la. Como posso ajudá-la hoje?\n",
      "Human: Como você está?\n",
      "AI:\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Estou bem, obrigado por perguntar. Estou aqui para ajudar com qualquer dúvida ou informação que você precise. Como posso ajudar?'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conversation.predict(input='Como você está?')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new ConversationChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mThe following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.\n",
      "\n",
      "Current conversation:\n",
      "Human: Como você está?\n",
      "AI: Estou bem, obrigado por perguntar. Estou aqui para ajudar com qualquer dúvida ou informação que você precise. Como posso ajudar?\n",
      "Human: Qual é o meu nome?\n",
      "AI:\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Desculpe, mas eu não tenho essa informação. Como posso ajudar com outra coisa?'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conversation.predict(input='Qual é o meu nome?')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ConversationTokenBufferMemory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.memory import ConversationTokenBufferMemory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai.chat_models import ChatOpenAI\n",
    "from langchain.chains.conversation.base import ConversationChain\n",
    "\n",
    "chat = ChatOpenAI()\n",
    "memory = ConversationTokenBufferMemory(llm=chat, max_token_limit=250)\n",
    "conversation = ConversationChain(\n",
    "    llm=chat,\n",
    "    memory=memory,\n",
    "    verbose=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new ConversationChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mThe following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.\n",
      "\n",
      "Current conversation:\n",
      "\n",
      "Human: Me conte uma história de 500 palavras\n",
      "AI:\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Claro! Aqui está uma história para você:\\n\\nEra uma vez, em um pequeno vilarejo nas montanhas, vivia uma jovem chamada Sofia. Ela era conhecida por sua bondade e generosidade, sempre ajudando os outros em momentos de necessidade. Um dia, enquanto caminhava pela floresta próxima ao vilarejo, Sofia encontrou um filhote de lobo ferido. Sem pensar duas vezes, ela o levou para casa e cuidou de seus ferimentos.\\n\\nCom o passar dos dias, o filhote de lobo se recuperou e se tornou o companheiro fiel de Sofia. Eles exploravam juntos a floresta, descobrindo segredos e tesouros escondidos. Mas nem tudo era pacífico no vilarejo, pois uma sombra misteriosa assombrava a região, deixando os moradores apreensivos.\\n\\nSofia decidiu investigar o mistério e descobriu que um bruxo malvado estava por trás dos eventos estranhos que estavam acontecendo na região. Determinada a proteger seu vilarejo, ela partiu em uma jornada arriscada para confrontar o bruxo e salvar todos que amava.\\n\\nCom a ajuda de seu fiel companheiro, o lobo, Sofia enfrentou desafios e perigos, provando sua coragem e determinação. Finalmente, ela conseguiu derrotar o bruxo e trazer paz de volta ao vilarejo. Os moradores agradeceram a jovem heroína por sua bravura e sacrifício, e ela se tornou uma lenda na região.\\n\\nE assim, Sofia e seu lobo viveram felizes para sempre, protegendo o vilarejo e espalhando bondade e esperança por onde passavam. A história de sua coragem e compaixão foi contada geração após geração, inspirando outros a seguirem seus passos e fazer o bem ao próximo.\\n\\nEspero que tenha gostado da história! Posso contar mais alguma para você?'"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conversation.predict(input='Me conte uma história de 500 palavras') # A história não é armazenada na memória pois possui mais que 250 tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new ConversationChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mThe following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.\n",
      "\n",
      "Current conversation:\n",
      "\n",
      "Human: Resuma a história anterior\n",
      "AI:\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Claro! Na história anterior, um grupo de exploradores descobriu uma antiga civilização perdida no meio da selva. Eles encontraram artefatos incríveis e aprenderam sobre a cultura e a história do povo que ali habitava. No entanto, também enfrentaram desafios e perigos durante a exploração. No final, conseguiram fazer importantes descobertas arqueológicas que mudaram nossa compreensão do passado.'"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conversation.predict(input='Resuma a história anterior') # Não consegue resumir a história por não ter sido armazenada na memória"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ConversationSummaryBufferMemory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.memory import ConversationSummaryBufferMemory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\annaf\\AppData\\Local\\Temp\\ipykernel_7700\\2852110069.py:5: LangChainDeprecationWarning: Please see the migration guide at: https://python.langchain.com/docs/versions/migrating_memory/\n",
      "  memory = ConversationSummaryBufferMemory(llm=chat, max_token_limit=250)\n"
     ]
    }
   ],
   "source": [
    "from langchain_openai.chat_models import ChatOpenAI\n",
    "from langchain.chains.conversation.base import ConversationChain\n",
    "\n",
    "chat = ChatOpenAI()\n",
    "memory = ConversationSummaryBufferMemory(llm=chat, max_token_limit=250)\n",
    "conversation = ConversationChain(\n",
    "    llm=chat,\n",
    "    memory=memory,\n",
    "    verbose=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new ConversationChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mThe following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.\n",
      "\n",
      "Current conversation:\n",
      "\n",
      "Human: Olá, meu nome é Anna\n",
      "AI:\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Olá, Anna! É um prazer conhecê-la. Como posso ajudá-la hoje?'"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conversation.predict(input='Olá, meu nome é Anna')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new ConversationChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mThe following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.\n",
      "\n",
      "Current conversation:\n",
      "Human: Olá, meu nome é Anna\n",
      "AI: Olá, Anna! É um prazer conhecê-la. Como posso ajudá-la hoje?\n",
      "Human: Me conte uma história de 500 palavras\n",
      "AI:\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Claro, vou contar uma história para você. Era uma vez, em um pequeno vilarejo no meio da floresta, vivia uma jovem chamada Maria. Maria era uma garota corajosa e curiosa, sempre em busca de aventuras. Um dia, enquanto explorava a floresta, Maria encontrou uma antiga caverna escondida entre as árvores. Curiosa, ela decidiu entrar na caverna para descobrir o que havia lá dentro.\\n\\nAo entrar na caverna, Maria se viu em um mundo totalmente diferente. As paredes eram cobertas de cristais brilhantes que emitiam uma luz mágica. No centro da caverna, havia um poço profundo, cuja água era tão clara que parecia refletir o céu. Maria se aproximou do poço e viu sua própria imagem refletida na água. Mas, para sua surpresa, a imagem começou a se mexer e se transformou em outra pessoa.\\n\\nA pessoa no reflexo era uma garota com cabelos dourados e olhos azuis brilhantes. Ela sorriu para Maria e estendeu a mão. Maria, sem hesitar, segurou a mão da garota e foi puxada para dentro do poço. Quando Maria abriu os olhos, viu-se em um reino mágico, cheio de criaturas místicas e paisagens deslumbrantes.\\n\\nA garota com quem Maria estava segurando a mão se apresentou como Lumi, a guardiã do reino mágico. Ela explicou que Maria havia sido escolhida para ajudar a salvar o reino de uma terrível maldição que estava prestes a destruí-lo. Maria aceitou o desafio e junto com Lumi, embarcou em uma jornada perigosa para encontrar os ingredientes necessários para quebrar a maldição.\\n\\nDurante a jornada, Maria e Lumi enfrentaram muitos desafios e perigos, mas juntas, elas conseguiram superar todos os obstáculos. No final, elas conseguiram encontrar os ingredientes e quebrar a maldição, salvando assim o reino mágico. Maria foi aclamada como heroína e recebeu a gratidão de todos os habitantes do reino.\\n\\nE assim, Maria voltou para casa, mas sempre guardando no coração as lembranças daquela incrível aventura no reino mágico. E desde então, ela nunca mais foi a mesma, pois havia descoberto o poder da coragem e da amizade. E foi assim que a história de Maria se tornou uma lenda contada pelas gerações futuras. E assim termina a história de Maria, a corajosa e destemida garota que salvou um reino mágico.'"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conversation.predict(input='Me conte uma história de 500 palavras') # A história não é armazenada na memória pois possui mais que 250 tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new ConversationChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mThe following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.\n",
      "\n",
      "Current conversation:\n",
      "System: A garota chamada Maria encontra uma caverna mágica e é transportada para um reino mágico, onde conhece a guardiã Lumi e embarca em uma jornada para salvar o reino de uma terrível maldição. Com coragem e amizade, Maria consegue quebrar a maldição e se torna uma heroína, deixando uma lenda para as gerações futuras.\n",
      "Human: Qual é o meu nome?\n",
      "AI:\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Desculpe, eu não sei o seu nome. Como posso te chamar?'"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conversation.predict(input='Qual é o meu nome?')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new ConversationChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mThe following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.\n",
      "\n",
      "Current conversation:\n",
      "System: A garota chamada Maria encontra uma caverna mágica e é transportada para um reino mágico, onde conhece a guardiã Lumi e embarca em uma jornada para salvar o reino de uma terrível maldição. Com coragem e amizade, Maria consegue quebrar a maldição e se torna uma heroína, deixando uma lenda para as gerações futuras.\n",
      "Human: Qual é o meu nome?\n",
      "AI: Desculpe, eu não sei o seu nome. Como posso te chamar?\n",
      "Human: O que eu pedi para você fazer inicialmente?\n",
      "AI:\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Você pediu para eu contar uma história sobre uma garota chamada Maria que encontra uma caverna mágica e é transportada para um reino mágico.'"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conversation.predict(input='O que eu pedi para você fazer inicialmente?')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
