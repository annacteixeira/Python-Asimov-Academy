{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Embeddings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Os Embeddings criam uma representação vetorial de um pedaço de texto. Isso é útil porque podemos pensar sobre o texto no espaço vetorial e fazer coisas como busca semântica, onde procuramos por pedaços de texto que são mais semelhantes no espaço vetorial, ou seja, que estão a uma distância menor.\n",
    "\n",
    "A classe Embeddings do LangChain é projetada para interagir com modelos de embedding de texto. Existem muitos modelos diferentes (OpenAI, Cohere, Hugging Face, etc) - esta classe é projetada para fornecer uma interface padrão para todos eles.\n",
    "\n",
    "A classe de Embeddings base em LangChain fornece dois métodos: um para realizar o embedding de documentos e outro para embedding de uma chamada. O primeiro recebe como entrada vários textos, enquanto o último recebe um único texto."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Embedding com OpenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\annaf\\AppData\\Local\\Temp\\ipykernel_12276\\1267886439.py:6: LangChainDeprecationWarning: The class `OpenAI` was deprecated in LangChain 0.0.10 and will be removed in 1.0. An updated version of the class exists in the :class:`~langchain-openai package and should be used instead. To use it run `pip install -U :class:`~langchain-openai` and import as `from :class:`~langchain_openai import OpenAI``.\n",
      "  llm = OpenAI(model='gpt-3.5-turbo-instruct')\n"
     ]
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "\n",
    "from langchain.llms import OpenAI\n",
    "\n",
    "llm = OpenAI(model='gpt-3.5-turbo-instruct')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import OpenAIEmbeddings\n",
    "\n",
    "embedding_model = OpenAIEmbeddings()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Embedding Documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings = embedding_model.embed_documents(\n",
    "    [\n",
    "        'Eu gosto de cachorros',\n",
    "        'Eu gosto de animais',\n",
    "        'O tempo está ruim lá fora'\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[-0.01189151406288147,\n",
       " 0.003109192941337824,\n",
       " -0.008564830757677555,\n",
       " -0.02842690609395504,\n",
       " -0.021332433447241783,\n",
       " 0.0040618618950247765,\n",
       " 0.007443683221936226,\n",
       " -0.014335982501506805,\n",
       " 0.0038933833129704,\n",
       " -0.007805146276950836]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embeddings[0][:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1536"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(embeddings[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1536 0.24662791192531586 -0.6614646911621094\n",
      "1536 0.23287081718444824 -0.654877245426178\n",
      "1536 0.23204080760478973 -0.6500335335731506\n"
     ]
    }
   ],
   "source": [
    "for emb in embeddings:\n",
    "    print(len(emb), max(emb), min(emb))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.float64(0.929192296639189)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "np.dot(embeddings[0], embeddings[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0 | 0.93 | 0.81 | \n",
      "0.93 | 1.0 | 0.8 | \n",
      "0.81 | 0.8 | 1.0 | \n"
     ]
    }
   ],
   "source": [
    "for i in range(len(embeddings)):\n",
    "    for j in range(len(embeddings)):\n",
    "        print(round(np.dot(embeddings[i], embeddings[j]), 2), end=' | ')\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Embedding Query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.005100993439555168,\n",
       " 0.003876505186781287,\n",
       " -0.0046824184246361256,\n",
       " -0.006441058591008186,\n",
       " -0.017842544242739677,\n",
       " 0.013619309291243553,\n",
       " 0.0015954270493239164,\n",
       " -0.002005412010475993,\n",
       " -0.002075695199891925,\n",
       " 0.005591413471847773]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pergunta = 'O que é um cachorro?'\n",
    "emb_query = embedding_model.embed_query(pergunta)\n",
    "\n",
    "emb_query[:10]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
